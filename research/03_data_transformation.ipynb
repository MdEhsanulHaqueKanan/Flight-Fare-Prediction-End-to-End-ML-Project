{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\Machine_Learning_Projects\\\\iNeuron internship\\\\Flight-Fare-Prediction-End-to-End-ML-Project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\Machine_Learning_Projects\\\\iNeuron internship\\\\Flight-Fare-Prediction-End-to-End-ML-Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlProject import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "# New Line\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "\n",
    "    # New Function Added\n",
    "    # https://github.com/yash1314/Flight-Price-Prediction/blob/main/src/utils.py\n",
    "    def convert_to_minutes(self, duration):\n",
    "        try:\n",
    "            hours, minute = 0, 0\n",
    "            for i in duration.split():\n",
    "                if 'h' in i:\n",
    "                    hours = int(i[:-1])\n",
    "                elif 'm' in i:\n",
    "                    minute = int(i[:-1])\n",
    "            return hours * 60 + minute\n",
    "        except :\n",
    "            return None \n",
    "\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    ## Note: You can add different data transformation techniques such as Scaler, PCA and all\n",
    "    #You can perform all kinds of EDA in ML cycle here before passing this data to the model\n",
    "\n",
    "    # I am only adding train_test_spliting cz this data is already cleaned up\n",
    "\n",
    "    # New Code Added Start\n",
    "    def initiate_data_transformation(self):\n",
    "        ## reading the data\n",
    "        # df = pd.read_csv(self.config.data_path)\n",
    "        # New Line\n",
    "        df = pd.read_excel(self.config.data_path)\n",
    "\n",
    "        logger.info('Read data completed')\n",
    "        logger.info(f'df dataframe head: \\n{df.head().to_string()}')\n",
    "\n",
    "        ## dropping null values\n",
    "        df.dropna(inplace = True)\n",
    "\n",
    "        ## Date of journey column transformation\n",
    "        df['journey_date'] = pd.to_datetime(df['Date_of_Journey'], format =\"%d/%m/%Y\").dt.day\n",
    "        df['journey_month'] = pd.to_datetime(df['Date_of_Journey'], format =\"%d/%m/%Y\").dt.month\n",
    "\n",
    "        ## encoding total stops.\n",
    "        df.replace({'Total_Stops': {'non-stop' : 0, '1 stop': 1, '2 stops': 2, '3 stops': 3, '4 stops': 4}}, inplace = True)\n",
    "\n",
    "        ## ecoding airline, source, and destination\n",
    "        df_airline = pd.get_dummies(df['Airline'], dtype=int)\n",
    "        df_source = pd.get_dummies(df['Source'],  dtype=int)\n",
    "        df_dest = pd.get_dummies(df['Destination'], dtype=int)\n",
    "\n",
    "        ## dropping first columns of each categorical variables.\n",
    "        df_airline.drop('Trujet', axis = 1, inplace = True)\n",
    "        df_source.drop('Banglore', axis = 1, inplace = True)\n",
    "        df_dest.drop('Banglore', axis = 1, inplace = True)\n",
    "\n",
    "        df = pd.concat([df, df_airline, df_source, df_dest], axis = 1)\n",
    "       \n",
    "        ## handling duration column\n",
    "        # df['duration'] = df['Duration'].apply(convert_to_minutes)\n",
    "        # New Line Added\n",
    "        df['duration'] = df['Duration'].apply(self.convert_to_minutes)\n",
    "        upper_time_limit = df.duration.mean() + 1.5 * df.duration.std()\n",
    "        df['duration'] = df['duration'].clip(upper = upper_time_limit)\n",
    "\n",
    "        ## encodign duration column\n",
    "        bins = [0, 120, 360, 1440]  # custom bin intervals for 'Short,' 'Medium,' and 'Long'\n",
    "        labels = ['Short', 'Medium', 'Long'] # creating labels for encoding\n",
    "\n",
    "        df['duration'] = pd.cut(df['duration'], bins=bins, labels=labels)\n",
    "        df.replace({'duration': {'Short':1, 'Medium':2, 'Long': 3}}, inplace = True)\n",
    "        \n",
    "        ## dropping the columns\n",
    "        cols_to_drop = cols_to_drop = ['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Route', 'Dep_Time', 'Arrival_Time', 'Duration', 'Additional_Info', 'Delhi', 'Kolkata']\n",
    "\n",
    "        df.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "        logger.info('df data transformation completed')\n",
    "        logger.info(f' transformed df data head: \\n{df.head().to_string()}')\n",
    "\n",
    "        # df.to_csv(self.data_transformation_config.transformed_data_file_path, index = False, header= True)\n",
    "        # New Line\n",
    "        df.to_excel(self.config.data_path, index = False, header= True)\n",
    "        # df.to_excel(self.config.transformed_data_file_path, index = False, header= True)\n",
    "        # df.to_excel(self.data_transformation_config.transformed_data_file_path, index = False, header= True)\n",
    "        logger.info(\"transformed data is stored\")\n",
    "        df.head(1)\n",
    "        ## splitting the data into training and target data\n",
    "        X = df.drop('Price', axis = 1)\n",
    "        y = df['Price']\n",
    "        \n",
    "        ## accessing the feature importance.\n",
    "        select = ExtraTreesRegressor()\n",
    "        select.fit(X, y)\n",
    "\n",
    "        # plt.figure(figsize=(12, 8))\n",
    "        # fig_importances = pd.Series(select.feature_importances_, index=X.columns)\n",
    "        # fig_importances.nlargest(20).plot(kind='barh')\n",
    "    \n",
    "        # ## specify the path to the \"visuals\" folder using os.path.join\n",
    "        # visuals_folder = 'visuals'\n",
    "        # if not os.path.exists(visuals_folder):\n",
    "        #     os.makedirs(visuals_folder)\n",
    "\n",
    "        # ## save the plot in the visuals folder\n",
    "        # plt.savefig(os.path.join(visuals_folder, 'feature_importance_plot.png'))\n",
    "        # logger.info('feature imp figure saving is successful')\n",
    "\n",
    "        ## further Splitting the data.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, shuffle = True) \n",
    "        logger.info('final splitting the data is successful')\n",
    "        \n",
    "\n",
    "        ## returning splitted data and data_path.\n",
    "        return (\n",
    "            X_train, \n",
    "            X_test, \n",
    "            y_train, \n",
    "            y_test,\n",
    "            self.config.data_path\n",
    "            # self.data_transformation_config.transformed_data_file_path\n",
    "        )    \n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "# class DataTransformation:\n",
    "#     def __init__(self, config: DataTransformationConfig):\n",
    "#         self.config = config\n",
    "\n",
    "    \n",
    "#     ## Note: You can add different data transformation techniques such as Scaler, PCA and all\n",
    "#     #You can perform all kinds of EDA in ML cycle here before passing this data to the model\n",
    "\n",
    "#     # I am only adding train_test_spliting cz this data is already cleaned up\n",
    "\n",
    "\n",
    "#     def train_test_spliting(self):\n",
    "#         data = pd.read_excel(self.config.data_path)\n",
    "\n",
    "#         # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "#         train, test = train_test_split(data)\n",
    "\n",
    "#         train.to_csv(os.path.join(self.config.root_dir, \"train.csv\"),index = False)\n",
    "#         test.to_csv(os.path.join(self.config.root_dir, \"test.csv\"),index = False)\n",
    "\n",
    "#         logger.info(\"Splited data into training and test sets\")\n",
    "#         logger.info(train.shape)\n",
    "#         logger.info(test.shape)\n",
    "\n",
    "#         print(train.shape)\n",
    "#         print(test.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-24 10:34:37,441: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-11-24 10:34:37,450: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-11-24 10:34:37,457: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2023-11-24 10:34:37,459: INFO: common: created directory at: artifacts]\n",
      "[2023-11-24 10:34:37,462: INFO: common: created directory at: artifacts/data_transformation]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-24 10:34:41,604: INFO: 1223503272: Read data completed]\n",
      "[2023-11-24 10:34:41,604: INFO: 1223503272: df dataframe head: \n",
      "   Total_Stops  Price  journey_date  journey_month  Air Asia  Air India  GoAir  IndiGo  Jet Airways  Jet Airways Business  Multiple carriers  Multiple carriers Premium economy  SpiceJet  Vistara  Vistara Premium economy  Chennai  Mumbai  Cochin  Hyderabad  New Delhi  duration\n",
      "0            0   3897            24              3         0          0      0       1            0                     0                  0                                  0         0        0                        0        0       0       0          0          1         2\n",
      "1            2   7662             1              5         0          1      0       0            0                     0                  0                                  0         0        0                        0        0       0       0          0          0         3\n",
      "2            2  13882             9              6         0          0      0       0            1                     0                  0                                  0         0        0                        0        0       0       1          0          0         3\n",
      "3            1   6218            12              5         0          0      0       1            0                     0                  0                                  0         0        0                        0        0       0       0          0          0         2\n",
      "4            1  13302             1              3         0          0      0       1            0                     0                  0                                  0         0        0                        0        0       0       0          0          1         2]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Date_of_Journey'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date_of_Journey'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mg:\\Machine_Learning_Projects\\iNeuron internship\\Flight-Fare-Prediction-End-to-End-ML-Project\\research\\03_data_transformation.ipynb Cell 10\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     data_transformation\u001b[39m.\u001b[39minitiate_data_transformation()\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[1;32mg:\\Machine_Learning_Projects\\iNeuron internship\\Flight-Fare-Prediction-End-to-End-ML-Project\\research\\03_data_transformation.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     data_transformation \u001b[39m=\u001b[39m DataTransformation(config\u001b[39m=\u001b[39mdata_transformation_config)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# data_transformation.train_test_spliting()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# New Line\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     data_transformation\u001b[39m.\u001b[39;49minitiate_data_transformation()\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[1;32mg:\\Machine_Learning_Projects\\iNeuron internship\\Flight-Fare-Prediction-End-to-End-ML-Project\\research\\03_data_transformation.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m df\u001b[39m.\u001b[39mdropna(inplace \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m## Date of journey column transformation\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mjourney_date\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m'\u001b[39;49m\u001b[39mDate_of_Journey\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mformat\u001b[39m \u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm/\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mday\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mjourney_month\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m'\u001b[39m\u001b[39mDate_of_Journey\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mformat\u001b[39m \u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm/\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mmonth\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m## encoding total stops.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date_of_Journey'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    # data_transformation.train_test_spliting()\n",
    "    # New Line\n",
    "    data_transformation.initiate_data_transformation()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
