{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\Machine_Learning_Projects\\\\iNeuron internship\\\\Flight-Fare-Prediction-End-to-End-ML-Project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\Machine_Learning_Projects\\\\iNeuron internship\\\\Flight-Fare-Prediction-End-to-End-ML-Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlProject import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "# New Line\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "\n",
    "    # New Function Added\n",
    "    # https://github.com/yash1314/Flight-Price-Prediction/blob/main/src/utils.py\n",
    "    def convert_to_minutes(duration):\n",
    "        try:\n",
    "            hours, minute = 0, 0\n",
    "            for i in duration.split():\n",
    "                if 'h' in i:\n",
    "                    hours = int(i[:-1])\n",
    "                elif 'm' in i:\n",
    "                    minute = int(i[:-1])\n",
    "            return hours * 60 + minute\n",
    "        except :\n",
    "            return None \n",
    "\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    ## Note: You can add different data transformation techniques such as Scaler, PCA and all\n",
    "    #You can perform all kinds of EDA in ML cycle here before passing this data to the model\n",
    "\n",
    "    # I am only adding train_test_spliting cz this data is already cleaned up\n",
    "\n",
    "    # New Code Added Start\n",
    "    def initiate_data_transformation(self):\n",
    "        ## reading the data\n",
    "        df = pd.read_csv(self.config.data_path)\n",
    "\n",
    "        logger.info('Read data completed')\n",
    "        logger.info(f'df dataframe head: \\n{df.head().to_string()}')\n",
    "\n",
    "        ## dropping null values\n",
    "        df.dropna(inplace = True)\n",
    "\n",
    "        ## Date of journey column transformation\n",
    "        df['journey_date'] = pd.to_datetime(df['Date_of_Journey'], format =\"%d/%m/%Y\").dt.day\n",
    "        df['journey_month'] = pd.to_datetime(df['Date_of_Journey'], format =\"%d/%m/%Y\").dt.month\n",
    "\n",
    "        ## encoding total stops.\n",
    "        df.replace({'Total_Stops': {'non-stop' : 0, '1 stop': 1, '2 stops': 2, '3 stops': 3, '4 stops': 4}}, inplace = True)\n",
    "\n",
    "        ## ecoding airline, source, and destination\n",
    "        df_airline = pd.get_dummies(df['Airline'], dtype=int)\n",
    "        df_source = pd.get_dummies(df['Source'],  dtype=int)\n",
    "        df_dest = pd.get_dummies(df['Destination'], dtype=int)\n",
    "\n",
    "        ## dropping first columns of each categorical variables.\n",
    "        df_airline.drop('Trujet', axis = 1, inplace = True)\n",
    "        df_source.drop('Banglore', axis = 1, inplace = True)\n",
    "        df_dest.drop('Banglore', axis = 1, inplace = True)\n",
    "\n",
    "        df = pd.concat([df, df_airline, df_source, df_dest], axis = 1)\n",
    "       \n",
    "        ## handling duration column\n",
    "        # df['duration'] = df['Duration'].apply(convert_to_minutes)\n",
    "        # New Line Added\n",
    "        df['duration'] = df['Duration'].apply(self.convert_to_minutes)\n",
    "        upper_time_limit = df.duration.mean() + 1.5 * df.duration.std()\n",
    "        df['duration'] = df['duration'].clip(upper = upper_time_limit)\n",
    "\n",
    "        ## encodign duration column\n",
    "        bins = [0, 120, 360, 1440]  # custom bin intervals for 'Short,' 'Medium,' and 'Long'\n",
    "        labels = ['Short', 'Medium', 'Long'] # creating labels for encoding\n",
    "\n",
    "        df['duration'] = pd.cut(df['duration'], bins=bins, labels=labels)\n",
    "        df.replace({'duration': {'Short':1, 'Medium':2, 'Long': 3}}, inplace = True)\n",
    "        \n",
    "        ## dropping the columns\n",
    "        cols_to_drop = cols_to_drop = ['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Route', 'Dep_Time', 'Arrival_Time', 'Duration', 'Additional_Info', 'Delhi', 'Kolkata']\n",
    "\n",
    "        df.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "        logger.info('df data transformation completed')\n",
    "        logger.info(f' transformed df data head: \\n{df.head().to_string()}')\n",
    "\n",
    "        df.to_csv(self.data_transformation_config.transformed_data_file_path, index = False, header= True)\n",
    "        logger.info(\"transformed data is stored\")\n",
    "        df.head(1)\n",
    "        ## splitting the data into training and target data\n",
    "        X = df.drop('Price', axis = 1)\n",
    "        y = df['Price']\n",
    "        \n",
    "        ## accessing the feature importance.\n",
    "        select = ExtraTreesRegressor()\n",
    "        select.fit(X, y)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        fig_importances = pd.Series(select.feature_importances_, index=X.columns)\n",
    "        fig_importances.nlargest(20).plot(kind='barh')\n",
    "    \n",
    "        ## specify the path to the \"visuals\" folder using os.path.join\n",
    "        visuals_folder = 'visuals'\n",
    "        if not os.path.exists(visuals_folder):\n",
    "            os.makedirs(visuals_folder)\n",
    "\n",
    "        ## save the plot in the visuals folder\n",
    "        plt.savefig(os.path.join(visuals_folder, 'feature_importance_plot.png'))\n",
    "        logger.info('feature imp figure saving is successful')\n",
    "\n",
    "        ## further Splitting the data.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, shuffle = True) \n",
    "        logger.info('final splitting the data is successful')\n",
    "        \n",
    "\n",
    "        ## returning splitted data and data_path.\n",
    "        return (\n",
    "            X_train, \n",
    "            X_test, \n",
    "            y_train, \n",
    "            y_test,\n",
    "            self.data_transformation_config.transformed_data_file_path\n",
    "        )    \n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "# class DataTransformation:\n",
    "#     def __init__(self, config: DataTransformationConfig):\n",
    "#         self.config = config\n",
    "\n",
    "    \n",
    "#     ## Note: You can add different data transformation techniques such as Scaler, PCA and all\n",
    "#     #You can perform all kinds of EDA in ML cycle here before passing this data to the model\n",
    "\n",
    "#     # I am only adding train_test_spliting cz this data is already cleaned up\n",
    "\n",
    "\n",
    "#     def train_test_spliting(self):\n",
    "#         data = pd.read_excel(self.config.data_path)\n",
    "\n",
    "#         # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "#         train, test = train_test_split(data)\n",
    "\n",
    "#         train.to_csv(os.path.join(self.config.root_dir, \"train.csv\"),index = False)\n",
    "#         test.to_csv(os.path.join(self.config.root_dir, \"test.csv\"),index = False)\n",
    "\n",
    "#         logger.info(\"Splited data into training and test sets\")\n",
    "#         logger.info(train.shape)\n",
    "#         logger.info(test.shape)\n",
    "\n",
    "#         print(train.shape)\n",
    "#         print(test.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-21 10:58:36,039: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-11-21 10:58:36,039: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-11-21 10:58:36,052: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2023-11-21 10:58:36,054: INFO: common: created directory at: artifacts]\n",
      "[2023-11-21 10:58:36,056: INFO: common: created directory at: artifacts/data_transformation]\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa1 in position 14: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mg:\\Machine_Learning_Projects\\iNeuron internship\\Flight-Fare-Prediction-End-to-End-ML-Project\\research\\03_data_transformation.ipynb Cell 10\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     data_transformation\u001b[39m.\u001b[39minitiate_data_transformation()\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[1;32mg:\\Machine_Learning_Projects\\iNeuron internship\\Flight-Fare-Prediction-End-to-End-ML-Project\\research\\03_data_transformation.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     data_transformation \u001b[39m=\u001b[39m DataTransformation(config\u001b[39m=\u001b[39mdata_transformation_config)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# data_transformation.train_test_spliting()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# New Line\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     data_transformation\u001b[39m.\u001b[39;49minitiate_data_transformation()\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[1;32mg:\\Machine_Learning_Projects\\iNeuron internship\\Flight-Fare-Prediction-End-to-End-ML-Project\\research\\03_data_transformation.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minitiate_data_transformation\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m## reading the data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdata_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mRead data completed\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdf dataframe head: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mdf\u001b[39m.\u001b[39mhead()\u001b[39m.\u001b[39mto_string()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1678\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1679\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[0;32m   1680\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1681\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mif\u001b[39;00m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype_backend\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[39m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:550\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:639\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:2021\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa1 in position 14: invalid start byte"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    # data_transformation.train_test_spliting()\n",
    "    # New Line\n",
    "    data_transformation.initiate_data_transformation()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
