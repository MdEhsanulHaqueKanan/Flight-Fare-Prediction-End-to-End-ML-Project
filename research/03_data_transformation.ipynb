{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\Machine_Learning_Projects\\\\iNeuron internship\\\\Flight-Fare-Prediction-End-to-End-ML-Project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\Machine_Learning_Projects\\\\iNeuron internship\\\\Flight-Fare-Prediction-End-to-End-ML-Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlProject import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "# New Line\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "\n",
    "    # New Function Added\n",
    "    # https://github.com/yash1314/Flight-Price-Prediction/blob/main/src/utils.py\n",
    "    def convert_to_minutes(duration):\n",
    "        try:\n",
    "            hours, minute = 0, 0\n",
    "            for i in duration.split():\n",
    "                if 'h' in i:\n",
    "                    hours = int(i[:-1])\n",
    "                elif 'm' in i:\n",
    "                    minute = int(i[:-1])\n",
    "            return hours * 60 + minute\n",
    "        except :\n",
    "            return None \n",
    "\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    ## Note: You can add different data transformation techniques such as Scaler, PCA and all\n",
    "    #You can perform all kinds of EDA in ML cycle here before passing this data to the model\n",
    "\n",
    "    # I am only adding train_test_spliting cz this data is already cleaned up\n",
    "\n",
    "    # New Code Added Start\n",
    "    def initiate_data_transformation(self):\n",
    "        ## reading the data\n",
    "        # df = pd.read_csv(self.config.data_path)\n",
    "        # New Line\n",
    "        df = pd.read_excel(self.config.data_path)\n",
    "\n",
    "        logger.info('Read data completed')\n",
    "        logger.info(f'df dataframe head: \\n{df.head().to_string()}')\n",
    "\n",
    "        ## dropping null values\n",
    "        df.dropna(inplace = True)\n",
    "\n",
    "        ## Date of journey column transformation\n",
    "        df['journey_date'] = pd.to_datetime(df['Date_of_Journey'], format =\"%d/%m/%Y\").dt.day\n",
    "        df['journey_month'] = pd.to_datetime(df['Date_of_Journey'], format =\"%d/%m/%Y\").dt.month\n",
    "\n",
    "        ## encoding total stops.\n",
    "        df.replace({'Total_Stops': {'non-stop' : 0, '1 stop': 1, '2 stops': 2, '3 stops': 3, '4 stops': 4}}, inplace = True)\n",
    "\n",
    "        ## ecoding airline, source, and destination\n",
    "        df_airline = pd.get_dummies(df['Airline'], dtype=int)\n",
    "        df_source = pd.get_dummies(df['Source'],  dtype=int)\n",
    "        df_dest = pd.get_dummies(df['Destination'], dtype=int)\n",
    "\n",
    "        ## dropping first columns of each categorical variables.\n",
    "        df_airline.drop('Trujet', axis = 1, inplace = True)\n",
    "        df_source.drop('Banglore', axis = 1, inplace = True)\n",
    "        df_dest.drop('Banglore', axis = 1, inplace = True)\n",
    "\n",
    "        df = pd.concat([df, df_airline, df_source, df_dest], axis = 1)\n",
    "       \n",
    "        ## handling duration column\n",
    "        # df['duration'] = df['Duration'].apply(convert_to_minutes)\n",
    "        # New Line Added\n",
    "        df['duration'] = df['Duration'].apply(self.convert_to_minutes)\n",
    "        upper_time_limit = df.duration.mean() + 1.5 * df.duration.std()\n",
    "        df['duration'] = df['duration'].clip(upper = upper_time_limit)\n",
    "\n",
    "        ## encodign duration column\n",
    "        bins = [0, 120, 360, 1440]  # custom bin intervals for 'Short,' 'Medium,' and 'Long'\n",
    "        labels = ['Short', 'Medium', 'Long'] # creating labels for encoding\n",
    "\n",
    "        df['duration'] = pd.cut(df['duration'], bins=bins, labels=labels)\n",
    "        df.replace({'duration': {'Short':1, 'Medium':2, 'Long': 3}}, inplace = True)\n",
    "        \n",
    "        ## dropping the columns\n",
    "        cols_to_drop = cols_to_drop = ['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Route', 'Dep_Time', 'Arrival_Time', 'Duration', 'Additional_Info', 'Delhi', 'Kolkata']\n",
    "\n",
    "        df.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "        logger.info('df data transformation completed')\n",
    "        logger.info(f' transformed df data head: \\n{df.head().to_string()}')\n",
    "\n",
    "        # df.to_csv(self.data_transformation_config.transformed_data_file_path, index = False, header= True)\n",
    "        # New Line\n",
    "        df.to_excel(self.data_transformation_config.transformed_data_file_path, index = False, header= True)\n",
    "        logger.info(\"transformed data is stored\")\n",
    "        df.head(1)\n",
    "        ## splitting the data into training and target data\n",
    "        X = df.drop('Price', axis = 1)\n",
    "        y = df['Price']\n",
    "        \n",
    "        ## accessing the feature importance.\n",
    "        select = ExtraTreesRegressor()\n",
    "        select.fit(X, y)\n",
    "\n",
    "        # plt.figure(figsize=(12, 8))\n",
    "        # fig_importances = pd.Series(select.feature_importances_, index=X.columns)\n",
    "        # fig_importances.nlargest(20).plot(kind='barh')\n",
    "    \n",
    "        # ## specify the path to the \"visuals\" folder using os.path.join\n",
    "        # visuals_folder = 'visuals'\n",
    "        # if not os.path.exists(visuals_folder):\n",
    "        #     os.makedirs(visuals_folder)\n",
    "\n",
    "        # ## save the plot in the visuals folder\n",
    "        # plt.savefig(os.path.join(visuals_folder, 'feature_importance_plot.png'))\n",
    "        # logger.info('feature imp figure saving is successful')\n",
    "\n",
    "        ## further Splitting the data.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, shuffle = True) \n",
    "        logger.info('final splitting the data is successful')\n",
    "        \n",
    "\n",
    "        ## returning splitted data and data_path.\n",
    "        return (\n",
    "            X_train, \n",
    "            X_test, \n",
    "            y_train, \n",
    "            y_test,\n",
    "            self.data_transformation_config.transformed_data_file_path\n",
    "        )    \n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "# class DataTransformation:\n",
    "#     def __init__(self, config: DataTransformationConfig):\n",
    "#         self.config = config\n",
    "\n",
    "    \n",
    "#     ## Note: You can add different data transformation techniques such as Scaler, PCA and all\n",
    "#     #You can perform all kinds of EDA in ML cycle here before passing this data to the model\n",
    "\n",
    "#     # I am only adding train_test_spliting cz this data is already cleaned up\n",
    "\n",
    "\n",
    "#     def train_test_spliting(self):\n",
    "#         data = pd.read_excel(self.config.data_path)\n",
    "\n",
    "#         # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "#         train, test = train_test_split(data)\n",
    "\n",
    "#         train.to_csv(os.path.join(self.config.root_dir, \"train.csv\"),index = False)\n",
    "#         test.to_csv(os.path.join(self.config.root_dir, \"test.csv\"),index = False)\n",
    "\n",
    "#         logger.info(\"Splited data into training and test sets\")\n",
    "#         logger.info(train.shape)\n",
    "#         logger.info(test.shape)\n",
    "\n",
    "#         print(train.shape)\n",
    "#         print(test.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-22 22:21:56,520: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-11-22 22:21:56,595: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-11-22 22:21:56,621: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2023-11-22 22:21:56,629: INFO: common: created directory at: artifacts]\n",
      "[2023-11-22 22:21:56,657: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2023-11-22 22:22:10,190: INFO: 1264642498: Read data completed]\n",
      "[2023-11-22 22:22:10,237: INFO: 1264642498: df dataframe head: \n",
      "       Airline Date_of_Journey    Source Destination                  Route Dep_Time  Arrival_Time Duration Total_Stops Additional_Info  Price\n",
      "0       IndiGo      24/03/2019  Banglore   New Delhi              BLR → DEL    22:20  01:10 22 Mar   2h 50m    non-stop         No info   3897\n",
      "1    Air India       1/05/2019   Kolkata    Banglore  CCU → IXR → BBI → BLR    05:50         13:15   7h 25m     2 stops         No info   7662\n",
      "2  Jet Airways       9/06/2019     Delhi      Cochin  DEL → LKO → BOM → COK    09:25  04:25 10 Jun      19h     2 stops         No info  13882\n",
      "3       IndiGo      12/05/2019   Kolkata    Banglore        CCU → NAG → BLR    18:05         23:30   5h 25m      1 stop         No info   6218\n",
      "4       IndiGo      01/03/2019  Banglore   New Delhi        BLR → NAG → DEL    16:50         21:35   4h 45m      1 stop         No info  13302]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "convert_to_minutes() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mg:\\Machine_Learning_Projects\\iNeuron internship\\Flight-Fare-Prediction-End-to-End-ML-Project\\research\\03_data_transformation.ipynb Cell 10\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     data_transformation\u001b[39m.\u001b[39minitiate_data_transformation()\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[1;32mg:\\Machine_Learning_Projects\\iNeuron internship\\Flight-Fare-Prediction-End-to-End-ML-Project\\research\\03_data_transformation.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     data_transformation \u001b[39m=\u001b[39m DataTransformation(config\u001b[39m=\u001b[39mdata_transformation_config)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# data_transformation.train_test_spliting()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# New Line\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     data_transformation\u001b[39m.\u001b[39;49minitiate_data_transformation()\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[1;32mg:\\Machine_Learning_Projects\\iNeuron internship\\Flight-Fare-Prediction-End-to-End-ML-Project\\research\\03_data_transformation.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df, df_airline, df_source, df_dest], axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m## handling duration column\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# df['duration'] = df['Duration'].apply(convert_to_minutes)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# New Line Added\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mDuration\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_to_minutes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m upper_time_limit \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mduration\u001b[39m.\u001b[39mmean() \u001b[39m+\u001b[39m \u001b[39m1.5\u001b[39m \u001b[39m*\u001b[39m df\u001b[39m.\u001b[39mduration\u001b[39m.\u001b[39mstd()\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Machine_Learning_Projects/iNeuron%20internship/Flight-Fare-Prediction-End-to-End-ML-Project/research/03_data_transformation.ipynb#X12sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mclip(upper \u001b[39m=\u001b[39m upper_time_limit)\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\2021\\.conda\\envs\\flightfareprediction\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: convert_to_minutes() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    # data_transformation.train_test_spliting()\n",
    "    # New Line\n",
    "    data_transformation.initiate_data_transformation()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
